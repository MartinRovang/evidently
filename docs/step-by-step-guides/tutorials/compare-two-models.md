# Compare two models

**TL;DR:** You can use Evidently to evaluate the performance of two models on the same data (in test / shadow deployment). Here is an example [Jupyter notebook](https://github.com/evidentlyai/evidently/blob/main/evidently/tutorials/ibm\_hr\_attrition\_model\_validation.ipynb).

## Tutorial - "What Is Your Model Hiding?"

![](<../../.gitbook/assets/image (1).png>)

In this tutorial, we train two **classification** models that predict employee attrition. Then, we compare and evaluate the differences in their performance despite the similar ROC AUC. The tutorial uses the **Probabilistic Classification** report.

* [Full text](https://evidentlyai.com/blog/tutorial-2-model-evaluation-hr-attrition) of the tutorial&#x20;
* Jupyter [notebook](https://github.com/evidentlyai/evidently/blob/main/evidently/tutorials/ibm\_hr\_attrition\_model\_validation.ipynb) w/source code
* Source [data](https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset) and description on Kaggle
